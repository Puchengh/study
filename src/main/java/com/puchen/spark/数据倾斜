数据倾斜
1)什么是数据倾斜？
    分布式的就会造成数据倾斜，—数据倾斜，此时Spark作业的性能会比期望差很多
    情况一：绝大多数task执行得都非常快，但个别task执行极慢。比如，总共有1000个task，997个task都在1分钟之内执行完了，但是剩余两三个task却要一两个小时。这种情况很常见。
    情况二：原本能够正常执行的Spark作业，某天突然报出OOM（内存溢出）异常，观察异常栈，是我们写的业务代码造成的。这种情况比较少见。
    ###数据倾斜的根本性原因：很多数据到同一个task任务里面去了，只会发生到shuffle过程中

2)如何去定位数据倾斜?
    数据倾斜只会发生在shuffle过程中。这里给大家罗列一些常用的并且可能会触发shuffle操作的算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等。出现数据倾斜时，可能就是你的代码中使用了这些算子中的某一个所导致的。
    ##通过界面去观察，spark UI界面，根据之前的stage的划分算法去定位数据倾斜的位置
  查看导致数据倾斜的key的数据分布情况
    如上操作已经找到数据倾斜的问题，接下来为了方便解决数据倾斜的问题，那么最好能定位到是那些key导致的数据倾斜
    采样
        val sampledPairs = pairs.sample(false, 0.1)
        val sampledWordCounts = sampledPairs.countByKey()
        sampledWordCounts.foreach(println(_))
    1. 如果是Spark SQL中的group by、join语句导致的数据倾斜，那么就查询一下SQL中使用的表的key分布情况。
    2. 如果是对Spark RDD执行shuffle算子导致的数据倾斜，那么可以在Spark作业中加入查看key分布的代码，比如RDD.countByKey()。然后对统计出来的各个key出现的次数，collect/take到客户端打印一下，就可以看到key的分布情况。
3)如何去解决数据倾斜?
    解决方案一：使用Hive ETL预处理数据
        用户行为分析  先是mapreduce-->换成了spark去处理这些数据  交互式的用户行为分析系统
        这个项目实际上是开发给产品经理去使用的
            前台 ---> JavaEE 管理系统  任意输入参数   点击按钮  这个参数用传到后台   会调用一个Action方法  导致spark任务运行
                可以查看准实时的查询
            后台 ---->  spark处理的是HDFS上数据  spark也有可能和HIVE里面的数据进行整合  进行交互式的job
                hive + mr 只能处理离线的数据      spark + hive  处理准实时的数据
        hive里面存在历史数据 本身的数据就不均匀   在hive提前把结果处理好数据
        这种方式让数据倾斜提前发生，简单完全规避了数据倾斜  使用场景少  治标不治本
    解决方案二：过滤少数导致倾斜的key
        方案适用场景：如果发现导致倾斜的key就少数几个，而且对计算本身的影响并不大的话，那么很适合使用这种方案。比如99%的key就对应10条数据，但是只有一个key对应了100万数据，从而导致了数据倾斜。
        解决方案：直接把这些数据过滤出去
    解决方案三：提高shuffle操作的并行度
        只有一个task  所有的数据只有这个task去处理  增加一个task可以缓解数据倾斜的问题  可以是万能的
        如果发生的是某个key确实出现的次数很多，这种解决方式是无效的
    解决方案四：两阶段聚合（局部聚合+全局聚合）
        已经提升了shuffle的并行度了 但是并不能真正的解决某个key出现过多的情况，
        给key打上随机数
    解决方案五：将reduce join转为map join
        在对RDD使用join类操作，或者是在Spark SQL中使用join语句时，而且join操作中的一个RDD或表的数据量比较小，其中的一个RDD较小的时候 比较适用于此方案
        方案的优点：对join操作导致的数据倾斜，效果非常好，因为根本就不会发生shuffle，也就根本不会发生数据倾斜。
        解决方案：
            普通的join是会走shuffle过程的，而一旦shuffle，就相当于会将相同key的数据拉取到一个shuffle read task中再进行join，此时就是reduce join。但是如果一个RDD是比较小的，则可以采用广播小RDD全量数据+map算子来实现与join同样的效果，也就是map join，此时就不会发生shuffle操作，也就不会发生数据倾斜。
    解决方案六：采样倾斜key并分拆join操作
        如果出现数据倾斜，是因为其中某一个RDD/Hive表中的少数几个key的数据量过大，而另一个RDD/Hive表中的所有key都分布比较均匀，那么采用这个解决方案是比较合适的。
        出现的问题:
            1）两个RDD数据量都很大
            2）导致数据倾斜的key 是较少的几个key
        解决思路:
            1)首先通过sample算子，进行采样，统计出来的每个key出现的次数。这样就知道是哪几个key导致的数据倾斜了
            2)将出现字数最多的key(导致数据倾斜的key)从原来的rdd中 拆分出来。形成一个单独的rdd，并给每个keu打上n以内的随机前缀
              不会导致数据倾斜的那部分单独形成一个rdd。那么到这儿，我们以前的一个rdd，就变成了两个rdd
              rdda1（里面倒数数据倾斜的key）  rdda2
            3)从另外的一个rdd里面过滤出来对应导致数据倾斜key的数据
              把过滤出来的数据又单独想成一个rdd,剩余的数据又形成了另外的一个rdd
              rdda1（导致数据倾斜的key对应的数据）  rddb2
            4)将rddb1扩大n倍 并且添加前缀
            5)rdda1 join rddb1 = result1
              union
              rdda2 join rddb2 = result2
              =result3
    解决方案七：使用随机前缀和扩容RDD进行join
        使用场景
            1两个RDD数据量都不小
            2导致数据倾斜的key又比较多
        解决思路
            这一种方案是针对有大量倾斜key的情况，没法将部分key拆分出来进行单独处理，因此只能对整个RDD进行数据扩容，对内存资源要求很高。
    解决方案八：多种方案组合使用
        在实践中根据各种不同的情况，灵活运用多种方案，来解决自己的数据倾斜问题。

shuffle调优(久远的版本存在的shuffle调优比较多 现在的版本的shuffle调优spark自己做了调整)
    面试的问题：说说spark shuffle的发展历程
        1）spark的shuffle真正的经历了好几个版本
            spark的shuffle是我们之间程序员经常调优的地方

            ##Spark 1.2以前，默认的shuffle计算引擎是HashShuffleManager。该ShuffleManager而HashShuffleManager有着一个非常严重的弊端，就是会产生大量的中间磁盘文件，进而由大量的磁盘IO操作影响了性能。
            ##在Spark 1.2以后的版本中，默认的ShuffleManager改成了SortShuffleManager。SortShuffleManager相较于HashShuffleManager来说，有了一定的改进。主要就在于，每个Task在进行shuffle操作时，虽然也会产生较多的临时磁盘文件，但是最后会将所有的临时文件合并（merge）成一个磁盘文件，因此每个Task就只有一个磁盘文件。在下一个stage的shuffle read task
              拉取自己的数据时，只要根据索引读取每个磁盘文件中的部分数据即可
                    ##SortShuffleManager的运行机制主要分成两种，一种是普通运行机制，另一种是bypass运行机制。当shuffle read task的数量小于等于
                      spark.shuffle.sort.bypassMergeThreshold参数的值时（默认为200），就会启用bypass机制。

            在executor中有几个cpu core 就有几个task执行





