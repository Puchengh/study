1.document的全量替换
    (1)语法和创建文档是一样的  付哦过document id不存在 那么就是创建，如果document id已经存在了，那么就是全量替换操作，替换document的json串内容
    (2)document是不可变的 如果要修改document的内容 第一种方式就是全量替换，直接对document重新建立索引，替换里面所有的内容
    (3)es会将老的document标记为deleted，然后新增我们给定的一个document，当我们创建越来越多的document的时候，es会在适当的时候在后台
    自动删除标记为deleted的document
2.document的强制创建
    (1)创建文档与全量替换的语法是一样的，有时我们只是想新建文档，不想替换文档，如果强制进行创建呢？
    (2)PUT /index/type/id?op_type-create, PUT /index/type/id/_create
3.document的删除
    (1)DELTE /index/type/id
    (2)不会理解物理删除，只会将其标记问deleted，当数据越来越多的时候，在后台自动删除

ES的并发冲突问题,多线程并发的执行 查询商品-->用户下单购买-->更新商品信息
1.有些场景下，其实是无所谓的，不care这个数据不正确的事情，比如说，我们如果就是只是简单
的将数据写入到ES中，无论数据是什么样的，都可以，还有些情况下，即时是算错了，也可以
2.当并发操作ES的线程越多 或者并发请求越多 或者是读取一份数据 供用户查询和操作的时间越长，
因为这段时间里很有可能数据在ES中已经被修改了，那么我们拿到的就是旧数据，基于旧数据去操作，后面结果肯定就错了.

###可剖析悲观锁和乐观锁两种并发控制方案0
悲观锁并发控制方案  常见于关系型数据库 比如MySQL   就是在各种情况下，都上锁，上锁之后，就只有一个想成可以操作这一条数据，
                                            当然，不同场景下，上的锁不同，行级锁，表级锁，读锁，写锁
乐观锁并发控制方案   乐观锁是不加锁的 每个线程都可以任意操作，引入一个版本号 version=1
                   如果版本号已经发生改变，怎么重新进行拉取数据计算  重新计算
    第一次创建document的时候 他的_version内部版本号就是1，以后，每次对这个document执行修改或者是删除操作，都会对这个_version版本号自动加1，哪怕是删除，
    也会对这条数据的版本号加1
    我们会发现，在删除一个document之后，可以从一个侧面证明，他不是立即物理删除掉的，因为他的一些版本号等信息还是保留着的.
    先删除一条document，在重新创建这条document，其实会在delete version基础之上，在把version号加1
    ##ES的后台  很多这种类似的replica同步请求 都是多线程异步的 也就是说多个修改请求之间是乱序的，没有顺序的，可能后修改的先到，先修改的后到
################################################################################################################################################################################################################################################
    基于ES内部的
    ES内部的多线程异步并发修改是，是基于自己的_version版本号进行乐观锁并发控制的，后修改先到先修改，中间的一些修改的数据会被忽略掉
    其中一个客户端，先跟新了一下这个数据，同时带上数据的版本号，确保说es中的数据的版本号，跟客户端中的数据的版本号是相同的，才能修改
    另外一个客户端，尝试version=1的数据去进行修改，同样带上version版本号，进行乐观锁的并发控制
    在客观所成功阻止并发问题的时候，尝试正确的完成更新
    基于最新的数据和版本号，去进行修改，修改后，带上最新的版本号
################################################################################################################################################################################################################################################
    基于自己设置的版本号更新
    ES提供了一个feature，就是说，你可以不用他提供的内部_version版本号来进行并发控制，可以基于你自己维护的一个版本号来进行并发控制。
    ?version=1
    ?version=1&version_type=externel
    version_type=externel  唯一的区别在于,_version，只有当你提供的version与es中的_version一模一样的时候，才可能进行修改，只要不一样，就报错
    当version_type=external的时候，只有当你提供的version比es中的_version大的时候，才能完成修改
    ES _version=1, ?version=1  才能更新成功
    ES _version=1, ?version>1&version_type=external,才能成功   比如说?version=2&version_type=external才能成功



1什么是 partial update?
PUT /index/type/id  创建文档&替换文档  就是一样的语法
一般对用到应用程序中  每次的执行流程基本都是这样的
(1)应用程序先发起一个get请求  获取到document  展示到前台界面  供用户查看和修改
(2)用户在前台界面修改数据，发送到后台
(3)后台代码，会将用户修改的数据在内存中进行执行，然后封装好修改好的全量数据
(4)然后发送PUT请求，到es中 进行全量替换
(5)es将老document标记为deleted 然后重新创建一个担心的饿document

partial update
post /index/type/id/_update
{
    "doc":{
        "要修改的少数举个field即可，不需要全量的数据"
    }
}
看起来，好像就比较方便了，每次就传递少数几个发生修改的field即可，不需要将全量的document数据发送过去

2图解 partial update 实现原理以及其优点
partial update



es其实是有个脚本支持的  可以基于groovy脚本实现各式各样的复杂操作 基于groovy脚本  如何执行partial update
es scripting module

(1)内置脚本(数字加1)
post /test_index/test_type/11/_update
{
    "script":"ctx._source.num+=1"
}
(2)外部脚本
ctx._source.tags+=new_tag
POST /test_index/test_type/10/_update
{
    "script":{
        "lang":"groovy",
        "file":"test-add-tags",
        "params":{
            "new_tag":"tag1"
        }
    }
}
(3)用脚本删除文档
ctx.op=ctx._source.num==count?'delete':'none'
POST /test_index/test_type/10/_update
{
    "script":{
        "lang":"groovy",
        "file":"test-delete-document",
        "params":{
            "count":"1"
        }
    }
}

(4)upsert操作  如果执行的document不存在 就执行uosert中的初始化操作，如果指定的document存在，就执行doc或者
              script指定的partial uodate操作
POST /test_index/test_type/11/_update
{
    "script":"ctx._source.num+=1",
    "upsert":{
        "num":0,
        "tags":[]
    }
}

################################################################################################################################################################################################################################################

POST /index/type/id/_update?retry_on_conflict=5&version=6
retry策略
1 再次获取document数据和最新版本号
2 基于最新版本号再次去更新  如果成功那么就OK了
3 如果失败 重复1和2两个步骤，最多重复几次呢？通过retry_on_conflict这个参数的值指定

################################################################################################################################################################################################################################################
    1.批量查询的好处
    就是一条一条的查询 比如说要查询100条数据  那么就要发送100次网络请求  这个开销还是很大的
    如果进行批量查询的话  查询100条数据  就要发送1次网络请求  网络请求的性能开销缩减到100倍
    2.mget的语法
    GET  /_mget
    {
        "docs":[
            {
            "_idnex":"test_index",
            "_type":"test_type",
            "_id":1
            },
            {
            "_idnex":"test_index",
            "_type":"test_type",
            "_id":2
            }
        ]
    }
    3.如果查询的document是一个idnex下的不同type中的话

    GET /test_index/_mget
    {
        "docs":[
            {
                "_type":"test_type",
                "_id":1
            },
            {
                "_type":"test_type",
                "_id":2
            }
        ]
    }
    4.如果要查询的数据都在同一个idnex下的同一个type下  最简单了
    GET /test_index/test_type/_mget
    {
        "ids":[1,2]
    }

    mget的重要性
    mget是很重要的  一般来说在进行查询的时候，如果一次性查询训多条数据的话  那么一定要用batch批量操作的api尽可能减少网络开销次数，
        可能可以将性能功能提升数倍 甚至数十倍  非常之重要
