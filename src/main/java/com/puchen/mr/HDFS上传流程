hadoop fs -put /
1.客户端namenode发送数据上传的请求  包含一个重要的信息  数据长度信息 206.7M
2.namenode接受到客户端的请求之后会做一系列的检查工作  读取配置信息默认128M
    1)文件是够存在，如果存在则报错
    2)上传文件的父目录是否存在 如果不存在则报错
    3)检查权限等
3.namenode检查通过会向客户端返回存储的节点信息
        返回节点有一个原则：就近原则  优先返回客户端所在的节点  返回同机架的节点  在返回不同机架的节点  减少网络传输
        blk_1:datanode01 datanode02
        blk_2:datanode02 datanode03
4.客户端接受namenode返回请求后  会进行一次逻辑切块
        逻辑切分：只是概念上的切分 并没有真正的进行文件切分 物理切分之前的准备 仅仅做一个切块的规划
        物理切块：真实的切分      0-127 127-200  两个块的切分
5.开始准备文件上传
6.构建通道 pipeline  根据块id依次进行构建  pipeline将一个块的所有存储节点构建成一个数据流通道
        客户端 01 - 02 - 04
7.开始真正进行文件上传  上传过程中边进行上传 边进行文件切块   真正的文件切分 物理切分
        上传的过程中会统计上传了多少  
        上传的时候以package为单位进行文件上传 一个package大小512KB
        先上传到datanode01中 会先写到缓存中，然后每接受到一个package就可以向下一个节点开始传递，同时缓存中的数据还持续向磁盘中写
8.当第一个块数据上传完成 则pipeline通道关闭 
9.上传第二个块  又重复 6 7 8的动作
10.所有的块上传完成之后会向客户端返回结果  客户端向namenode返回信息  告知客户端上传成功 则namenode需要更新元数据        

注意：文件上传过程中如果有一个节点块上传失败，那么立即进行一次重试，如果还是失败 会将失败的节点从pipeline中剔除  并报告给namenode
    最大极限是至少有一个节点上传成功，如果副本节点都失败，会向namenode重新构建pipeline
    剩下的副本在集群上传成功后进行异步复制

    在数据上传的时候，一般情况下肯定会返回一个客户端所在节点，因为客户端所在节点不存在网络传输，上传失败的可能性小，这个时候可以保证数据至少上传成功一个节点的可能性大